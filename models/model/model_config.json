{
  "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
  "model_type": "LlamaForCausalLM",
  "device": "cuda:0",
  "quantization": "float16"
}